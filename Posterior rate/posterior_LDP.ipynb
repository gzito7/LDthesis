{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d0c612",
   "metadata": {},
   "source": [
    "# Posterior and Rate Function Demo\n",
    "\n",
    "the **rate function as a regularisation term**.\n",
    "\n",
    "- the posterior is given by:\n",
    "  \\[\n",
    "  p_n(\\vartheta) \\;\\propto\\; e^{-a_n \\ell_\\vartheta}\\,p_{\\text{prior}},\n",
    "  \\]\n",
    "  and the Large Deviation Principle (Proposition 4.1) states that the posterior concentrates\n",
    "  with rate function\n",
    "  \\[\n",
    "  \\ell_\\vartheta + I_{F^{(L+1)}} - \\inf(\\ell_\\vartheta + I_{F^{(L+1)}}).\n",
    "  \\]\n",
    "\n",
    "- we simulate the **rate function** \\(I_{F^{(L+1)}}\\) for a simple single-input network\n",
    "  (Linear and ReLU activations), using the helper functions from `ld_rate_sim.py`.\n",
    "\n",
    "- Then, we show how this rate acts as a **regularizer** in the loss square\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e32ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ld_rate_single_input import compute_IK, compute_IF_from_IK, make_IF_regularizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f98c2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(np.float64(0.0), 0.0003167863292496964),\n",
       " (np.float64(0.3), 0.14198631274515439),\n",
       " (np.float64(0.6), 0.41102680957243387),\n",
       " (np.float64(0.8999999999999999), 0.7069472329383795),\n",
       " (np.float64(1.2), 1.0066224992917594),\n",
       " (np.float64(1.5), 1.3034545946889153),\n",
       " (np.float64(1.7999999999999998), 1.5951524375683666),\n",
       " (np.float64(2.1), 1.881302904380866),\n",
       " (np.float64(2.4), 2.1616897244710094),\n",
       " (np.float64(2.6999999999999997), 2.436587187344768),\n",
       " (np.float64(3.0), 2.7062405710970308)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute IK and IF for Linear activation (L=2, K1=1.0)\n",
    "k_grid, IK_vals = compute_IK(L=2, K1=1.0, activation=\"linear\", a=0.5, k_grid_max=4.0, k_grid_size=200)\n",
    "\n",
    "# Evaluate IF(y) for a range of norms\n",
    "y_norms = np.linspace(0, 3.0, 11)\n",
    "IF_vals = [compute_IF_from_IK(y, k_grid, IK_vals) for y in y_norms]\n",
    "\n",
    "list(zip(y_norms, IF_vals))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca100e",
   "metadata": {},
   "source": [
    "## Using IF as a Regularizer\n",
    "\n",
    "We now construct a callable `IF_reg(y)` that evaluates the rate function penalty for any output vector `y`.\n",
    "\n",
    "This corresponds to adding \\(I_F\\) to the empirical loss, as in the posterior rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8db77319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.19), 1.1398715100606056, np.float64(0.30398715100606055))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build IF regularizer\n",
    "IF_reg = make_IF_regularizer(L=2, K1=1.0, activation=\"linear\", a=0.5, k_grid_max=4.0, k_grid_size=200)\n",
    "\n",
    "# Toy example: output y and target t\n",
    "y = np.array([1.2, -0.3, 0.5])\n",
    "t = np.array([1.0, 0.0, 0.0])\n",
    "\n",
    "sq_loss = 0.5 * np.sum((y - t)**2)\n",
    "IF_pen = IF_reg(y)\n",
    "gamma = 0.1\n",
    "total = sq_loss + gamma * IF_pen\n",
    "\n",
    "sq_loss, IF_pen, total\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
